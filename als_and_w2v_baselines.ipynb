{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим ещё пару базовых решений, качество которых хотелось бы в итоге превзойти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "LAUNCHER_SAMPLE_PATH = 'launcher_sample.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем тот же самый класс для разбиения датасета на обучение и тест, чтобы всё было по-честному."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserBasedShuffleSplit(object):\n",
    "    \"\"\"\n",
    "    Cross-validation for recommenders splits test and train sets\n",
    "    across items of the same users: i.e., if item I of user U is\n",
    "    present in a test set, user U (with some other items) must\n",
    "    also be present in the corresponding train set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, array, test_user_size=0.1, test_item_size=1, n_splits=1):\n",
    "        assert isinstance(test_user_size, (int, float)), 'test_user_size must be int or float'\n",
    "        assert isinstance(test_item_size, int), 'test_user_size must be integer'\n",
    "\n",
    "        self.array = array[['user', 'item']].copy()\n",
    "        self.array['index'] = np.arange(len(self.array))\n",
    "        self.test_user_size = test_user_size\n",
    "        self.test_item_size = test_item_size\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def get_splittable_users(self):\n",
    "        \"\"\"\n",
    "        Returns all suitable users (those who have sufficient\n",
    "        amount of items).\n",
    "        \"\"\"\n",
    "        users, counts = np.unique(self.array['user'], return_counts=True)\n",
    "        return users[counts > self.test_item_size]\n",
    "\n",
    "    def get_subset_to_split(self, splittable_users):\n",
    "        \"\"\"\n",
    "        Returns a subset of original `array` which contains users\n",
    "        with sufficient amount of items to split into two sets.\n",
    "        \"\"\"\n",
    "        if isinstance(self.test_user_size, float):\n",
    "            test_user_size = int(self.test_user_size * len(splittable_users))\n",
    "        else:\n",
    "            test_user_size = self.test_user_size\n",
    "        return self.array[np.in1d(\n",
    "            self.array['user'],\n",
    "            np.random.choice(splittable_users, test_user_size, replace=False)\n",
    "        )]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_splits\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.splittable_users = self.get_splittable_users()\n",
    "        for _ in range(self.n_splits):\n",
    "            splittable_subset = self.get_subset_to_split(self.splittable_users)\n",
    "            test_idx = []\n",
    "            for user, subset in splittable_subset.groupby('user'):\n",
    "                test_idx.append(self.split_user(subset))\n",
    "\n",
    "            test_idx = np.hstack(test_idx)\n",
    "            train_idx = np.setdiff1d(np.arange(len(self.array)), test_idx)\n",
    "            yield train_idx, test_idx\n",
    "\n",
    "    def split_user(self, subset):\n",
    "        return np.random.choice(subset['index'], self.test_item_size, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И качество будем измерять так же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_score_at_k(df_test, df_predict, k):\n",
    "    df_test_dict = {user: user_items for user, user_items in df_test.groupby('user')}\n",
    "    scores = []\n",
    "    for user, recommendations in df_predict.groupby('user'):\n",
    "        user_items = df_test_dict.get(user, [])\n",
    "        if len(user_items) == 0:\n",
    "            continue\n",
    "        intersection = np.intersect1d(user_items['item'], recommendations['item'].iloc[:k])\n",
    "        n_matches = float(len(intersection))\n",
    "        scores.append(n_matches / min(k, len(user_items)))\n",
    "    if not scores:\n",
    "        raise Exception(\"Users from test and train set don't intersect!\")\n",
    "    else:\n",
    "        return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные и разбиваем на обучение и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12156</td>\n",
       "      <td>5527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7982</td>\n",
       "      <td>15525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5614</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465</td>\n",
       "      <td>14937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465</td>\n",
       "      <td>9556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user   item\n",
       "0  12156   5527\n",
       "1   7982  15525\n",
       "2   5614  13600\n",
       "3    465  14937\n",
       "4    465   9556"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher = pd.read_csv(LAUNCHER_SAMPLE_PATH)\n",
    "launcher.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = UserBasedShuffleSplit(launcher, test_user_size=1000, test_item_size=10)\n",
    "train_idx, test_idx = next(iter(cv))\n",
    "\n",
    "df_train = launcher.iloc[train_idx]\n",
    "df_test = launcher.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12156</td>\n",
       "      <td>5527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7982</td>\n",
       "      <td>15525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5614</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465</td>\n",
       "      <td>14937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465</td>\n",
       "      <td>9556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user   item\n",
       "0  12156   5527\n",
       "1   7982  15525\n",
       "2   5614  13600\n",
       "3    465  14937\n",
       "4    465   9556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393272</th>\n",
       "      <td>22</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385711</th>\n",
       "      <td>22</td>\n",
       "      <td>6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392536</th>\n",
       "      <td>22</td>\n",
       "      <td>5055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380764</th>\n",
       "      <td>22</td>\n",
       "      <td>8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380757</th>\n",
       "      <td>22</td>\n",
       "      <td>1778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item\n",
       "393272    22  1145\n",
       "385711    22  6964\n",
       "392536    22  5055\n",
       "380764    22  8882\n",
       "380757    22  1778"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания базовых решений воспользуемся реализациями популярных алгоритмов ALS и Word2Vec из библиотеки Spark ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('als_and_w2v_baselines').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|user| item|rating|\n",
      "+----+-----+------+\n",
      "|   0| 3719|     1|\n",
      "|   0| 1376|     1|\n",
      "|   0| 6736|     1|\n",
      "|   0| 1367|     1|\n",
      "|   0| 1332|     1|\n",
      "|   0|20577|     1|\n",
      "|   0|21315|     1|\n",
      "|   0| 6659|     1|\n",
      "|   0| 1338|     1|\n",
      "|   0|21496|     1|\n",
      "|   0| 1334|     1|\n",
      "|   0| 1454|     1|\n",
      "|   0|20579|     1|\n",
      "|   0| 4943|     1|\n",
      "|   0| 1373|     1|\n",
      "|   0|13535|     1|\n",
      "|   0| 1379|     1|\n",
      "|   0|20174|     1|\n",
      "|   0|21258|     1|\n",
      "|   0|11478|     1|\n",
      "+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "als_train = spark.createDataFrame(df_train)\n",
    "als_train = als_train.withColumn('rating', f.lit(1))\n",
    "\n",
    "als_train.cache()\n",
    "als_train.orderBy('user').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|user| item|\n",
      "+----+-----+\n",
      "|  22| 8882|\n",
      "|  22| 1227|\n",
      "|  22| 7056|\n",
      "|  22|   34|\n",
      "|  22| 5055|\n",
      "|  22| 1145|\n",
      "|  22|10504|\n",
      "|  22| 1778|\n",
      "|  22|11058|\n",
      "|  22| 6964|\n",
      "|  27| 4048|\n",
      "|  27|10841|\n",
      "|  27|10113|\n",
      "|  27|17436|\n",
      "|  27| 4755|\n",
      "|  27|18861|\n",
      "|  27|10789|\n",
      "|  27|12259|\n",
      "|  27|12865|\n",
      "|  27|18334|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "als_test = spark.createDataFrame(df_test)\n",
    "\n",
    "als_test.cache()\n",
    "als_test.orderBy('user').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и сделаем предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "als = ALS(rank=10, maxIter=5, implicitPrefs=True, seed=1707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o63.getParam.\n: java.util.NoSuchElementException: Param coldStartStrategy does not exist.\n\tat org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:601)\n\tat org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:601)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.ml.param.Params$class.getParam(params.scala:600)\n\tat org.apache.spark.ml.PipelineStage.getParam(Pipeline.scala:42)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1829bf82a400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mals_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mals_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mJava\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transfer_params_to_java\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparamMap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_java_param_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparamMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_make_java_param_pair\u001b[0;34m(self, param, value)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolveParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mjava_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mjava_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/e.sushinskiy/anaconda/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o63.getParam.\n: java.util.NoSuchElementException: Param coldStartStrategy does not exist.\n\tat org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:601)\n\tat org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:601)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.ml.param.Params$class.getParam(params.scala:600)\n\tat org.apache.spark.ml.PipelineStage.getParam(Pipeline.scala:42)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "als_model = als.fit(als_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = als_model.transform(train)\n",
    "\n",
    "predictions.cache()\n",
    "predictions.orderBy(f.col('user'), desc('prediction')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|user|               items|\n",
      "+----+--------------------+\n",
      "|   0|[11478, 1332, 133...|\n",
      "|   1|[1042, 11120, 117...|\n",
      "|   2|[10386, 10813, 11...|\n",
      "|   3|[10741, 10948, 11...|\n",
      "|   4|[10495, 10581, 10...|\n",
      "|   5|[10181, 12330, 14...|\n",
      "|   6|[10348, 10579, 10...|\n",
      "|   7|[10730, 11012, 11...|\n",
      "|   8|[10495, 10572, 10...|\n",
      "|   9|[10411, 11882, 12...|\n",
      "|  10|[10752, 10759, 10...|\n",
      "|  11|[11015, 11131, 11...|\n",
      "|  12|[10063, 10251, 10...|\n",
      "|  13|[10034, 10948, 11...|\n",
      "|  14|[10285, 12656, 13...|\n",
      "|  15|[10338, 11657, 11...|\n",
      "|  16|[12249, 12505, 12...|\n",
      "|  17|[10948, 11132, 11...|\n",
      "|  18|[10319, 10320, 10...|\n",
      "|  19|[10948, 11209, 12...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_train = spark.createDataFrame(df_train)\\\n",
    "    .select(f.col('user'), f.col('item').cast(t.StringType()))\\\n",
    "    .orderBy('user', 'item')\\\n",
    "    .groupBy('user')\\\n",
    "    .agg(f.collect_list('item').alias('items'))\n",
    "\n",
    "w2v_train.cache()\n",
    "w2v_train.orderBy('user').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: long (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item2Vec = Word2Vec(vectorSize=10, minCount=0, inputCol='items', outputCol='result', windowSize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item2Vec = item2Vec.fit(w2v_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод transform возвращает векторные представления наборов приложений покупателей (усреднение векторов всех приложений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user: bigint, items: array<string>, result: vector]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = item2Vec.transform(w2v_train)\n",
    "result.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+\n",
      "|user|               items|              result|\n",
      "+----+--------------------+--------------------+\n",
      "|  26|[10040, 10948, 11...|[-0.1730425206323...|\n",
      "|  29|[10140, 12249, 13...|[0.06771651612451...|\n",
      "| 474|[10179, 10961, 11...|[-0.0976660244844...|\n",
      "| 964|[10229, 12734, 13...|[-0.2425984864433...|\n",
      "|1677|[10923, 10924, 13...|[-0.1463075963950...|\n",
      "|1697|[12234, 12939, 12...|[-0.2148559339344...|\n",
      "|1806|[12826, 13977, 14...|[-0.2647646979793...|\n",
      "|1950|[12193, 1227, 140...|[-0.1251080517585...|\n",
      "|2040|[10326, 10348, 11...|[-0.1833049550100...|\n",
      "|2214|[10780, 12940, 13...|[-0.1368040009623...|\n",
      "|2250|[10720, 11658, 13...|[-0.1577911119569...|\n",
      "|2453|[10010, 10016, 12...|[-0.0538457855158...|\n",
      "|2509|[10020, 11658, 11...|[0.10259561520069...|\n",
      "|2529|[10187, 10565, 11...|[-0.1790539913746...|\n",
      "|2927|[10627, 10948, 11...|[-0.3726906167343...|\n",
      "|3091|[10058, 10670, 10...|[-0.1290517181320...|\n",
      "|3506|[11033, 11599, 11...|[-0.2458223892442...|\n",
      "|3764|[10948, 11189, 12...|[0.09631343744695...|\n",
      "|4590|[1065, 10719, 115...|[-0.2718207108167...|\n",
      "|4823|[10614, 10948, 12...|[-0.0120304212744...|\n",
      "+----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод getVectors возвращает векторные представления приложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| word|              vector|\n",
      "+-----+--------------------+\n",
      "|10292|[0.04394483566284...|\n",
      "|19125|[-0.0762670785188...|\n",
      "| 5451|[0.03049250692129...|\n",
      "| 4018|[0.09986700862646...|\n",
      "|17319|[-0.6657822728157...|\n",
      "|20778|[-0.0970354080200...|\n",
      "|17079|[-0.5113746523857...|\n",
      "| 9936|[0.06084300205111...|\n",
      "|13172|[-0.0211183037608...|\n",
      "|17840|[-0.1792943924665...|\n",
      "|10304|[-0.3674074113368...|\n",
      "|20323|[-0.1198502331972...|\n",
      "|16997|[-0.8670586943626...|\n",
      "|14779|[-0.2956146597862...|\n",
      "|15822|[-0.8894290328025...|\n",
      "| 4056|[-0.0083574801683...|\n",
      "|15469|[-0.0352986119687...|\n",
      "|12209|[-0.2829174101352...|\n",
      "|21299|[-0.0479806289076...|\n",
      "|  710|[-0.0756228566169...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item2Vec.getVectors().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
